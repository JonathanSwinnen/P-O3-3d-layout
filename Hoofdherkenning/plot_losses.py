import matplotlib.pyplot as plt
import time


def plt_losses(epochs, tr_loss, val_score, store_path="./saved_models/losses.png"):
    tr_losses = tr_loss.copy()
    val_scores = val_score.copy()
    epochs = range(epochs)

    # add values
    plt.plot(epochs, tr_losses, 'r', label='Training losses')
    plt.plot(epochs, val_scores, 'g', label='Validation score')

    # labels
    plt.xlabel('Epochs')
    plt.ylabel('Value')
    plt.title('Training parameters in function of epochs')
    plt.legend()

    # save plot as .png
    plt.savefig(store_path)


if __name__ == "__main__":
    training_loss = [0.3035, 0.2611, 0.2024, 0.1709, 0.2103, 0.1699, 0.1452, 0.2076, 0.1784, 0.163, 0.1284, 0.1346,
                     0.1558, 0.1098, 0.1412, 0.1568, 0.1641, 0.1701, 0.1511, 0.182, 0.171, 0.1756, 0.1072, 0.1585,
                     0.1223, 0.1053, 0.1415, 0.1452, 0.147, 0.173, 0.1577, 0.1445, 0.1317, 0.1407, 0.1614, 0.1502,
                     0.1815, 0.1542, 0.173, 0.1359, 0.1174, 0.15, 0.1187, 0.1983, 0.1286, 0.1891, 0.1543, 0.1303,
                     0.1348, 0.1291, 0.1534, 0.1368, 0.1493, 0.2527, 0.1229, 0.1303, 0.1604, 0.1699, 0.1429, 0.1197,
                     0.1457, 0.1309, 0.118, 0.0998, 0.1043, 0.1829, 0.1282, 0.0964, 0.1496, 0.1275, 0.1771, 0.1378,
                     0.1673, 0.1715, 0.139, 0.1414, 0.1263, 0.1163, 0.1423, 0.1408, 0.089, 0.1473, 0.1701, 0.1248,
                     0.1464, 0.1795, 0.139, 0.1743, 0.1872, 0.182, 0.156, 0.1398, 0.1866, 0.1328, 0.1605, 0.1613,
                     0.1486, 0.108, 0.1413, 0.1563]
    val_score = [0.30823312274047304, 0.3250738607377422, 0.5202089651506774, 0.6582906063722105, 0.7377542908094368,
               0.7384109703861937, 0.7481786341083293, 0.7369726263746923, 0.7593080279778461, 0.7624964787035572,
               0.7652129007845508, 0.764260112022867, 0.7642358863840297, 0.7642214134031412, 0.7660393082365697,
               0.7660383460473041, 0.7660391342883207, 0.7660389171571148, 0.7660389208063787, 0.7660388776234218,
               0.7660389122914295, 0.7660389110750082, 0.7660388812726858, 0.7660388928286883, 0.7660389208063787,
               0.7660389025600589, 0.766038893436899, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203,
               0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203, 0.7660388946533203]

    plt_losses(100, training_loss, val_score, "./saved_models/PO3_v3/losses.png")
